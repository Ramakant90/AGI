{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1M6mc3HRMv4d0Hz2JW7u7HVeUwGdI-y2N",
      "authorship_tag": "ABX9TyMiz23JyMTceymTZjTDb0wF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramakant90/AGI/blob/main/RamakantBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZUr4QCaq6oi",
        "outputId": "abe4f9df-59ad-4a0a-8587-d2ba9058f28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… intents.json file created!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "intents = {\n",
        "  \"intents\": [\n",
        "    {\"tag\": \"greeting\",\n",
        "     \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"Namaste\", \"What's up?\"],\n",
        "     \"responses\": [\"Hello!\", \"Namaste!\", \"Hi there! How can I help?\"]\n",
        "    },\n",
        "    {\"tag\": \"bye\",\n",
        "     \"patterns\": [\"Bye\", \"See you\", \"Goodbye\"],\n",
        "     \"responses\": [\"Alvida!\", \"Bye!\", \"See you soon!\"]\n",
        "    },\n",
        "    {\"tag\": \"thanks\",\n",
        "     \"patterns\": [\"Thanks\", \"Thank you\", \"Shukriya\"],\n",
        "     \"responses\": [\"You're welcome!\", \"Koi baat nahi!\", \"Happy to help!\"]\n",
        "    },\n",
        "    {\"tag\": \"age\",\n",
        "     \"patterns\": [\"What is your age?\", \"How old are you?\"],\n",
        "     \"responses\": [\"Main AI hoon, umar ka koi matlab nahi ðŸ˜„\"]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "with open(\"intents.json\", \"w\") as f:\n",
        "    json.dump(intents, f, indent=4)\n",
        "\n",
        "print(\"âœ… intents.json file created!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision nltk\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download the missing resource\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# ðŸ”¹ Helper functions\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_sentence:\n",
        "            bag[idx] = 1.0\n",
        "    return bag\n",
        "\n",
        "# ðŸ”¹ Load dataset\n",
        "with open(\"intents.json\", \"r\") as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?', '!', '.', ',']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "    y_train.append(tags.index(tag))\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# ðŸ”¹ Model Design\n",
        "class ChatBotModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ChatBotModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "# ðŸ”¹ Training\n",
        "input_size = len(X_train[0])\n",
        "hidden_size = 8\n",
        "output_size = len(tags)\n",
        "model = ChatBotModel(input_size, hidden_size, output_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    X = torch.from_numpy(X_train)\n",
        "    y = torch.from_numpy(y_train).long()\n",
        "\n",
        "    output = model(X)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 200 == 0:\n",
        "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"âœ… Training complete. Saving model...\")\n",
        "\n",
        "data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"input_size\": input_size,\n",
        "    \"hidden_size\": hidden_size,\n",
        "    \"output_size\": output_size,\n",
        "    \"all_words\": all_words,\n",
        "    \"tags\": tags\n",
        "}\n",
        "\n",
        "torch.save(data, \"chatbot_data.pth\")\n",
        "print(\"ðŸ’¾ Model saved as chatbot_data.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZXGNmGarHvy",
        "outputId": "fca78085-60b5-44f2-9464-494a698a52df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [200/1000], Loss: 0.7011\n",
            "Epoch [400/1000], Loss: 0.0833\n",
            "Epoch [600/1000], Loss: 0.0163\n",
            "Epoch [800/1000], Loss: 0.0067\n",
            "Epoch [1000/1000], Loss: 0.0036\n",
            "âœ… Training complete. Saving model...\n",
            "ðŸ’¾ Model saved as chatbot_data.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "    bag = np.zeros(len(all_words), dtype=np.float32)\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_sentence:\n",
        "            bag[idx] = 1.0\n",
        "    return bag\n",
        "\n",
        "# ðŸ”¹ Load model\n",
        "FILE = \"chatbot_data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data[\"all_words\"]\n",
        "tags = data[\"tags\"]\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "class ChatBotModel(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ChatBotModel, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "model = ChatBotModel(input_size, hidden_size, output_size)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "with open(\"intents.json\", \"r\") as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "bot_name = \"RamakantBot\"\n",
        "print(f\"{bot_name} tayyar hai! Type 'quit' to exit.\\n\")\n",
        "\n",
        "while True:\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = torch.from_numpy(X).float()\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=0)\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=0)\n",
        "    prob = probs[predicted.item()]\n",
        "\n",
        "    if prob.item() > 0.7:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: Mujhe samajh nahi aaya ðŸ˜…\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c26x-G6zrj5I",
        "outputId": "294482f2-3801-428e-ac10-2bb017a640f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RamakantBot tayyar hai! Type 'quit' to exit.\n",
            "\n",
            "RamakantBot: Hello!\n",
            "RamakantBot: Mujhe samajh nahi aaya ðŸ˜…\n",
            "RamakantBot: Mujhe samajh nahi aaya ðŸ˜…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "na12Mucksv0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}